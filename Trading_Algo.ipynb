{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install alpaca-trade-api pandas numpy schedule\n",
        "!pip install praw pandas transformers torch numpy google-play-scraper\n",
        "!pip install google-play-scraper"
      ],
      "metadata": {
        "id": "F7dCqW2lB1Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4c8mxXpu8Le"
      },
      "outputs": [],
      "source": [
        "from alpaca_trade_api.rest import REST\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import praw\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from google_play_scraper import reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Algorithm"
      ],
      "metadata": {
        "id": "BIsqpZy8M-xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scrape Reddit 1\n",
        "def scrape_reddit(client_id, client_secret, user_agent, query=\"Chipotle\", limit=1000):\n",
        "    reddit = praw.Reddit(\n",
        "        client_id=client_id,\n",
        "        client_secret=client_secret,\n",
        "        user_agent=user_agent\n",
        "    )\n",
        "    posts = []\n",
        "    for submission in reddit.subreddit(\"all\").search(query, limit=limit):\n",
        "        if not submission.stickied:\n",
        "            posts.append(submission.title + \" \" + submission.selftext)\n",
        "    return pd.DataFrame({'text': posts})\n",
        "\n",
        "#Scrape Google Play reviews 2\n",
        "def scrape_google_play(app_id=\"com.chipotle.ordering\", limit=200):\n",
        "    review_data, _ = reviews(\n",
        "        app_id,\n",
        "        lang='en',\n",
        "        country='us',\n",
        "        count=limit\n",
        "    )\n",
        "    return pd.DataFrame({'text': [r['content'] for r in review_data]})\n",
        "\n",
        "#Load sentiment model HAVE TO CHANGE THIS\n",
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "label_map = {\n",
        "    \"LABEL_0\": \"negative\",\n",
        "    \"LABEL_1\": \"neutral\",\n",
        "    \"LABEL_2\": \"positive\"\n",
        "}\n",
        "\n",
        "sentiment_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    top_k=None\n",
        ")\n",
        "\n",
        "#Sentiment analysis\n",
        "def analyze_sentiment(text):\n",
        "    try:\n",
        "        result = sentiment_pipeline(text)[0]\n",
        "        scores = {label_map[entry['label']]: entry['score'] for entry in result}\n",
        "        return max(scores, key=scores.get)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return \"neutral\"\n",
        "\n",
        "\n",
        "client_id = \"M8D3he3NjOj8Y4Z3PF3gzw\"\n",
        "client_secret = \"77fOIkC8gN_SC5g_-2TDXKKZZFENXg\"\n",
        "user_agent = \"chipotle-analysis by u/No-Chemistry-203\"\n",
        "\n",
        "#Scrape data\n",
        "print(\"Scraping Reddit...\")\n",
        "reddit_df = scrape_reddit(client_id, client_secret, user_agent, query=\"Chipotle\", limit=1000)\n",
        "\n",
        "print(\"Scraping Google Play...\")\n",
        "google_df = scrape_google_play(app_id=\"com.chipotle.ordering\", limit=200)\n",
        "\n",
        "#Combine and analyze\n",
        "combined_df = pd.concat([reddit_df, google_df], ignore_index=True)\n",
        "combined_df['sentiment'] = combined_df['text'].apply(analyze_sentiment)\n",
        "\n",
        "#Export\n",
        "#output_path = r\"C:\\Users\\dpods\\Downloads\\chipotle_2sentiment.csv\"\n",
        "#combined_df.to_csv(output_path, index=False, encoding='utf-8')\n",
        "#print(f\"Analysis complete, File saved to: {output_path}\")\n",
        "\n",
        "#Check\n",
        "print(\"Reddit rows:\", len(reddit_df))\n",
        "print(\"Google Play rows:\", len(google_df))\n",
        "print(\"Total combined rows:\", len(combined_df))\n",
        "\n",
        "summary = combined_df['sentiment'].value_counts()\n",
        "print(summary)\n",
        "\n",
        "sentiment_counts = combined_df['sentiment'].value_counts()"
      ],
      "metadata": {
        "id": "kxQhwRhUNN7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uptrend Algorithm"
      ],
      "metadata": {
        "id": "KPtdBqGcM7Un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# variables\n",
        "API_KEY = \"PK0CBK5ROYJZAAEBUWKB\"\n",
        "SECRET_KEY = \"Tip93sYY2IAz6Mxgx99A3qBzvlXlVrU3grqhhd9P\"\n",
        "BASE_URL = \"https://paper-api.alpaca.markets\"\n",
        "STOCK_SYMBOL = \"CMG\"\n",
        "TRADE_AMOUNT = 100"
      ],
      "metadata": {
        "id": "e8ZwP1WavAAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to API\n",
        "api = REST(API_KEY, SECRET_KEY, base_url=BASE_URL)"
      ],
      "metadata": {
        "id": "YNHoxgW8vAgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch 50-day MA function\n",
        "def get_price_data(symbol):\n",
        "    end_date = datetime.utcnow() - timedelta(days=1)\n",
        "    start_date = end_date - timedelta(days=90)\n",
        "\n",
        "    bars = api.get_bars(\n",
        "        symbol,\n",
        "        timeframe=\"1Day\",\n",
        "        start=start_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
        "        end=end_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
        "    ).df\n",
        "\n",
        "    df = bars.copy()\n",
        "    df['MA_50'] = df['close'].rolling(window=50).mean()\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "SdhVgOoWvAjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function checks if the most recent closing price is greater than the 50-day MA\n",
        "def is_uptrend(df):\n",
        "    latest_close = df['close'].iloc[-1]\n",
        "    latest_ma = df['MA_50'].iloc[-1]\n",
        "    return latest_close > latest_ma, latest_close, latest_ma"
      ],
      "metadata": {
        "id": "n6cdMylJ0Qjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# place buy function\n",
        "def place_buy(symbol, current_price):\n",
        "    qty = round(TRADE_AMOUNT / current_price, 4)\n",
        "    order = api.submit_order(\n",
        "        symbol=symbol,\n",
        "        qty=qty,\n",
        "        side=\"buy\",\n",
        "        type=\"market\",\n",
        "        time_in_force=\"day\"\n",
        "    )\n",
        "    return qty\n"
      ],
      "metadata": {
        "id": "9Y4tcjwWvAlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sell function\n",
        "\n",
        "def place_sell(symbol, qty):\n",
        "    try:\n",
        "        order = api.submit_order(\n",
        "            symbol=symbol,\n",
        "            qty=qty,\n",
        "            side='sell',\n",
        "            type='market',\n",
        "            time_in_force='day'\n",
        "        )\n",
        "        print(f\"Sell order placed for {qty} shares of {symbol}\")\n",
        "        return order\n",
        "    except Exception as e:\n",
        "        print(f\"Error placing sell order for {symbol}: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "8vvGm3iITJ1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# csv log\n",
        "def log_trade(symbol, qty, price, ma_50):\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"symbol\": symbol,\n",
        "        \"price\": price,\n",
        "        \"ma_50\": ma_50,\n",
        "        \"qty\": qty,\n",
        "        \"trade_value\": round(qty * price, 2)\n",
        "    }\n",
        "\n",
        "    log_file = \"trade_log.csv\"\n",
        "    if os.path.exists(log_file):\n",
        "        df = pd.read_csv(log_file)\n",
        "        df = pd.concat([df, pd.DataFrame([log_entry])], ignore_index=True)\n",
        "    else:\n",
        "        df = pd.DataFrame([log_entry])\n",
        "\n",
        "    df.to_csv(log_file, index=False)\n",
        "    print(f\"Trade logged for {symbol}\")\n"
      ],
      "metadata": {
        "id": "L8pBzgtzy6Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "account = api.get_account()\n",
        "\n",
        "print(\"API Connected\")\n",
        "print(f\"Account status: {account.status}\")\n",
        "print(f\"Equity: ${account.equity}\")\n",
        "print(f\"Buying power: ${account.buying_power}\")"
      ],
      "metadata": {
        "id": "2P6c-QqX8BtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "- make list of stocks\n",
        "- have run_bot loop through until it finds one with uptrend.\n",
        "- If it does, buy and move on to sell loop"
      ],
      "metadata": {
        "id": "KJX2hgp5hwO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main\n",
        "positions = {} # check positions\n",
        "\n",
        "def run_bot(symbol):\n",
        "    df = get_price_data(symbol)\n",
        "\n",
        "    if df.empty or df['MA_50'].isna().all():\n",
        "        print(f\"No valid data for {symbol}. Possibly rate-limited or stock symbol is invalid.\")\n",
        "        return\n",
        "\n",
        "    uptrend, price, ma = is_uptrend(df)\n",
        "\n",
        "    if symbol in positions:\n",
        "      entry_price = positions[symbol]['entry_price']\n",
        "      qty = positions[symbol]['qty']\n",
        "      change_pct = (price - entry_price) / entry_price\n",
        "\n",
        "        # if change_pct >= 0.02 # this is our take profit exit\n",
        "          # print(f\"SELL {symbol} + 2%. Entry {en}\")\n",
        "\n",
        "    if uptrend:\n",
        "        print(f\"{symbol} is in uptrend. Price: {price:.2f}, MA50: {ma:.2f}\")\n",
        "        qty = place_trade(symbol, price)\n",
        "        log_trade(symbol, qty, price, ma)\n",
        "    else:\n",
        "        print(f\"{symbol} is NOT in uptrend. Price: {price:.2f}, MA50: {ma:.2f}\")\n"
      ],
      "metadata": {
        "id": "ZXXxasVWy6Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_bot(STOCK_SYMBOL)"
      ],
      "metadata": {
        "id": "zXKu5fnTzEXo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}